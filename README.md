# cybersecurity-thesis
Final year research work.
Abstract
Cyberbullying has become a common problem on social media sites, harming victimsâ€™ reputations, causing psychological distress, and having long-term negative effects. The main
goal of current detection techniques is to find harmful individual messages; however, they do not take into account persistent harassment by particular profiles. Furthermore, 
victims are rarely given proactive support by current systems, leaving them with few options for defense and reaction.
In order to detect persistent offenders, this thesis suggests designing and implementing an NLP-Driven Cyberbullying Detection and Support Agent that monitors and assesses user 
profiles in addition to identifying harmful messages. To categorize abusive content, the agent uses Natural Language Processing (NLP) methods, utilising machine learning and 
deep learning models like SVM, CNNs, LSTMs, and transformers (e.g., BERT). The system can differentiate between isolated incidents and regular bullying patterns thanks to the 
introduction of a ratio- and threshold-based mechanism that aggregates offender behavior at the profile level.
The proposed agent includes a user-support module that offers real-time alerts, recommendations for protective actions (such as reporting, blocking, and muting), and reminders 
for follow-up. The system will be expanded into a Chrome browser extension to improve usability and facilitate real-world applications, enabling users to receive proactive
assistance while browsing social media platforms.
This research is anticipated to yield a novel framework for detecting cyberbullying at the profile level, an intelligent support agent aimed at enhancing user safety, and a
prototype extension that illustrates practical deployment. This study integrates detection with actionable support to enhance online safety, thus contributing to cybersecurity,
natural language processing, and human-computer interaction (HCI).
